---
title: "North Beach Fort Cam/Big Cojo Cam Daily"
author: "Ryan Wang"
date: "2023-07-29"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)

library(tidyverse)
library(tidymodels)
library(dplyr)
library(here)
library(zoo)
library(tseries)
library(stats)
library(astsa)
library(forecast)
library(car)
library(MASS)
library(finalfit) 
library(ggplot2)
library(forecast)
library(lubridate)
library(astsa)
library(dynlm)
library(knitr)
library(nlme)

nbf_day_complete <- read.csv(here("data", "nbf_day_complete.csv"))
bc_day_complete <- read.csv(here("data", "bc_day_complete.csv"))
```


### North Beach Fort Cam - Plotting and Analyzing the Time Series
```{r}
# take a subset for analysis  
# and split into training and testing set.

nbf_day_ts_total_1 <- ts(nbf_day_complete$number_of_objects)
nbf_day_ts_train_1 <- ts(nbf_day_complete$number_of_objects[(1):(58)]) 
nbf_day_ts_test_1 <- ts(nbf_day_complete$number_of_objects[(59):(62)])


time_nbf_day_ts_train <- strptime(nbf_day_complete$time[(1):(58)], "%m/%d/%Y")
tsplot(x=time_nbf_day_ts_train, y=nbf_day_ts_train_1, xlab = 'time', ylab = 'Count')
```


```{r}
# apply Box-Cox transformation to make the variance constant
bc_nbf_day_ts_total_1<-boxcox(lm((nbf_day_ts_train_1+0.01) ~ 1))

lambda_bc_nbf_day_ts <- bc_nbf_day_ts_total_1$x[which.max(bc_nbf_day_ts_total_1$y)]
nbf_day_ts_train <- BoxCox(nbf_day_ts_train_1+0.01, lambda_bc_nbf_day_ts)
nbf_day_ts_test <- BoxCox(nbf_day_ts_test_1+0.01, lambda_bc_nbf_day_ts)
nbf_day_ts_total <- BoxCox(nbf_day_ts_total_1+0.01, lambda_bc_nbf_day_ts)

tsplot(x=time_nbf_day_ts_train,y=nbf_day_ts_train, xlab = 'time', ylab = 'Transformed Count')
```

Thus, I firstly perform the Box-Cox transformation to make constant variance with $\lambda = 0.222$. 

```{r}
acf2(nbf_day_ts_train_1, max.lag = 25)

adf.test(nbf_day_ts_train_1)
Box.test(nbf_day_ts_train_1, type = c("Ljung-Box"), fitdf = 0)
```

```{r}
acf2(nbf_day_ts_train, max.lag = 25)

adf.test(nbf_day_ts_train)
Box.test(nbf_day_ts_train, type = c("Ljung-Box"), fitdf = 0)
```
ACF plot and PACF plots do not show significant spikes, meaning the time series is a white noise.

The p-value of Ljung-Box tests are greater than 0.05, which also indicate that the time series is a white noise.

Possible cause of the time series being a white noise:
1. Insufficient data. the data might have a monthly seasonality component, but there are less than 60 data points. Also, both June and August have missing data.  
2. Outliers. The presence of of outliers can obscure the underlying autocorrelation patterns.

### Big Cojo Cam - Plotting and Analyzing the Time Series
```{r}
# take a subset for analysis  
# and split into training and testing set.

bc_day_ts_total_1 <- ts(bc_day_complete$number_of_objects)
bc_day_ts_train_1 <- ts(bc_day_complete$number_of_objects[(1):(45)]) 
bc_day_ts_test_1 <- ts(bc_day_complete$number_of_objects[(46):(49)], start =46)


time_bc_day_ts_train <- strptime(bc_day_complete$time[(1):(45)], "%m/%d/%Y")
tsplot(x=time_bc_day_ts_train, y=bc_day_ts_train_1, xlab = 'time', ylab = 'Count')
```

```{r}
acf2(bc_day_ts_train_1, max.lag = 25)

adf.test(bc_day_ts_train_1)
Box.test(bc_day_ts_train_1, type = c("Ljung-Box"), fitdf = 0)
```

The ACF plot shows significant spikes at seasonal lags (7), which is a sign of seasonality. 
ACF shows a geometric decay and PACF has a significant spike at lag 1 with no significant spike following. Thus, it can be a AR(1) process. 
ACF and PACF also show geometric decay over seasonal lags, meaning it can be a SARMA process and the exact value of the parameter cannot be determined from the ACF/PACF plot.


```{r}
diff_bc_day_ts_train <- diff(bc_day_ts_train_1, 7)
tsplot(diff_bc_day_ts_train, ylab = "Differenced Count")

acf2(diff_bc_day_ts_train, max.lag = 30)
Box.test(diff_bc_day_ts_train, type = c("Ljung-Box"), fitdf = 0)
```

ACF and PACF almost show no significant spike. Ljung-Box gives a p-value of 0.4753 so I fail to reject the null that the time series is a white noise.

After taking the difference at lag 7, the time series has no autocorrelation.

```{r}
# auto.arima(bc_day_ts_train_1, max.order = 4, trace=TRUE) # Best model:  ARIMA(0,1,1)
bc_day_model_auto <-arima(bc_day_ts_train_1, order=c(0,1,1))

#### Model diagnosis - auto.arima ####
# 1. Normality test
residual_bc_day_model_auto <- residuals(bc_day_model_auto)
hist(residual_bc_day_model_auto,density=20,breaks=20,col="blue",xlab="",main = "Histogram of Residual",prob=TRUE)

# 2. Correlation test
acf2(residual_bc_day_model_auto, max.lag = 30) 
# ACF plot / PACF plot show almost no significant spike.

Box.test(residual_bc_day_model_auto, type = c("Box-Pierce"))
Box.test(residual_bc_day_model_auto, lag = 7, type = c("Box-Pierce"))

# Thus, I conclude that the residual of this model is a Guassian white noise.
summary(bc_day_model_auto)
```


```{r}
bc_day_model_1 <-arima(bc_day_ts_train_1, order=c(1,0,0),seasonal = list(order=c(0,0,1),period=7))

#### Model diagnosis - auto.arima ####
# 1. Normality test
residual_bc_day_model_1 <- residuals(bc_day_model_1)
hist(residual_bc_day_model_1,density=20,breaks=20,col="blue",xlab="",main = "Histogram of Residual",prob=TRUE)

# 2. Correlation test
acf2(residual_bc_day_model_1, max.lag = 30) 
# ACF plot / PACF plot show almost no significant spike.

Box.test(residual_bc_day_model_1, type = c("Box-Pierce"))
Box.test(residual_bc_day_model_1, lag = 7, type = c("Box-Pierce"))
# Both the Box-Pierce test and the Ljung-Box test give p-vlaues greater than 0.05. I fail to reject the null
 
# Thus, I conclude that the residual of this model is a Guassian white noise.
summary(residual_bc_day_model_1)
```


```{r}
bc_day_model_2 <-arima(bc_day_ts_train_1, order=c(0,0,1),seasonal = list(order=c(0,0,1),period=7))

#### Model diagnosis - auto.arima ####
# 1. Normality test
residual_bc_day_model_2 <- residuals(bc_day_model_2)
hist(residual_bc_day_model_2,density=20,breaks=20,col="blue",xlab="",main = "Histogram of Residual",prob=TRUE)

# 2. Correlation test
acf2(residual_bc_day_model_2, max.lag = 30) 
# ACF plot / PACF plot show almost no significant spike.

Box.test(residual_bc_day_model_2, type = c("Box-Pierce"))
Box.test(residual_bc_day_model_2, lag = 7, type = c("Box-Pierce"))

# Thus, I conclude that the residual of this model is a Guassian white noise.
summary(residual_bc_day_model_2)
```

```{r}
### Summary of the created model.
result <- AIC(bc_day_model_auto, bc_day_model_1, bc_day_model_2) 
models <- list(bc_day_model_auto, bc_day_model_1, bc_day_model_2) 
result$BIC <- sapply(models, BIC) 
kable(result, digits = 2, align = "c")
```

```{r}
# Plot the fitted values with raw data
bc_day_fitted_1 <- bc_day_ts_train_1 - residual_bc_day_model_auto
ts.plot(bc_day_ts_train_1, main = 'model auto, fitted vs actual')
points(bc_day_fitted_1, type = "l", col = 2, lty = 2)

bc_day_fitted_2 <- bc_day_ts_train_1 - residual_bc_day_model_1
ts.plot(bc_day_ts_train_1, main = 'model 1, fitted vs actual')
points(bc_day_fitted_2, type = "l", col = 2, lty = 2)
```

To summarize, three models are equivalently good in the correlation test (there is no significant correlation left in the residuals of the three models). The model given by the auto.arima function is much better in terms of the AIC/BIC value for its model simplicity but it is worse in capturing the changing pattern of the time series.

It seems that bc_day_model_auto has higher precision (degree of reproducibility) and bc_day_model_1 has higher accuracy (degree of closeness to true value). 

### Big Cojo Cam - Forecast
```{r}
# Plot the forecast values with actual data
pred_1 <- sarima.for(bc_day_ts_train_1, n.ahead=4, plot.all=F, p=0, d=1, q=1, P=0, D=0, Q=0, S=0)
lines(bc_day_ts_test_1, col="blue")
points(bc_day_ts_test_1, col="blue")
legend("bottomleft", pch=1, col=c("red", "blue"), legend=c("Predicted Values", "True Values"))


pred_2 <- sarima.for(bc_day_ts_train_1, n.ahead=4, plot.all=F, p=1, d=0, q=0, P=0, D=0, Q=1, S=7)
lines(bc_day_ts_test_1, col="blue")
points(bc_day_ts_test_1, col="blue")
legend("bottomleft", pch=1, col=c("red", "blue"), legend=c("Predicted Values", "True Values"))
```

bc_day_model_1 also performs better in prediction as it captures the changing pattern of the time series.

